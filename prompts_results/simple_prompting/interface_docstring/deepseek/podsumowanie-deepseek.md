# Podsumowanie analizy pokrycia testów jednostkowych (Model: DeepSeek)
# Kontekst: interfejs + docstring
# Strategia promptowania: simple prompting

## coverage.py
- missing: 1
- partial: 1
- coverage: 99%

## mutmut.py
⠼ 217/217  🎉 103 🫥 0  ⏰ 0  🤔 0  🙁 114  🔇 0

## Ogólne informacje

Liczba wszystkich własnych scenariuszy: 54

- Testy wygenerowane przez LLM: 34
<br/> <strong>NOTKA: pojawiają się testy z kilkoma asercjami</strong>
- Testy zakończone powodzeniem: 33
- Testy zakończone niepowodzeniem: 1


- Liczba pokrytych scenariuszy testowych: 46
- Liczba niepotrzebnych testów: 0
- Liczba scenariuszy niepokrytych: 24
- Szybkość: wysoka (minuta)

## Plusy

- 33/34 testów przechodzi. Jeden test zawiera błąd logiczny.
- Testy są dobrze zorganizowane i podzielone na różne klasy.
- Testy mają przejrzyste i czytelne nazwy metod.
- (!) Testy pokrywają bardzo dużo scenariuszy testowych względem liczby testów. Genialna proporcja.

## Minusy

- Pisze komentarze w kodzie mimo prośby o ich braku.
- Model wykazuje mały potencjał na sprawdzanie edge casów, zrobił to tylko w jednym przypadku.
- Brakuje testów związanych z wydajnością, np. dodanie lub usunięcie tysięcy produktów.
- Brakuje testów odpornościowych, np. bardzo duże liczby, wartości typu `None`, `inf`, `NaN`.
- Brakuje większej różnorodności inputów

## Pomijane scenariusze

- testy precyzji obliczeń
- test wydajnościowe / odpornościowe

