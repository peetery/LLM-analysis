# Podsumowanie analizy pokrycia testÃ³w jednostkowych (Model: DeepSeek)
# Kontekst: full context
# Strategia promptowania: chain-of-thought

## coverage.py
- missing: 1
- partial: 1
- coverage: 99%

## mutmut.py
â ‹ 217/217  ğŸ‰ 108 ğŸ«¥ 0  â° 0  ğŸ¤” 0  ğŸ™ 109  ğŸ”‡ 0

## Rezultaty
- Statement coverage: 99%
- Branch coverage: 98%
- Mutation score: 50%

## OgÃ³lne informacje

Liczba wszystkich wÅ‚asnych scenariuszy: 54

- Testy wygenerowane przez LLM: 61
- Testy zakoÅ„czone powodzeniem: 61
- Testy zakoÅ„czone niepowodzeniem: 0


- Liczba pokrytych scenariuszy testowych: 46
- Liczba niepotrzebnych testÃ³w: 15
<br/>NOTKA: NiektÃ³re z tych testÃ³w moÅ¼na uznaÄ‡ za ciekawe przypadki, ale jednak wiÄ™kszoÅ›Ä‡ rzeczywiÅ›cie jest niepotrzebna.
- Liczba scenariuszy niepokrytych: 8
- SzybkoÅ›Ä‡: wysoka (2 minuty 50 sekund na 3 prompty)

## Plusy

- 61/61 testÃ³w przechodzi.
- Model pokryÅ‚ prawie wszystkie typowe scenariusze testowe (z wyjÄ…tkiem 1).
- Model pokryÅ‚ prawie wszystkie typowe corner case'y.
- Testy sÄ… dobrze zorganizowane i Å›wietnie podzielone na pojedyncze asercje.
- Testy majÄ… przejrzyste i czytelne nazwy metod.
- Model wykazuje potencjaÅ‚ do wykrywania edge case'Ã³w. W kilku przypadkach sprawdzaÅ‚ skrajne wartoÅ›ci.

## Minusy

- Brakuje testÃ³w zwiÄ…zanych z wydajnoÅ›ciÄ…, np. dodanie lub usuniÄ™cie tysiÄ™cy produktÃ³w.
- Brakuje testÃ³w odpornoÅ›ciowych, np. bardzo duÅ¼e liczby, wartoÅ›ci typu `None`, `inf`, `NaN`.
- Brakuje wiÄ™kszej rÃ³Å¼norodnoÅ›ci inputÃ³w.

## Pomijane scenariusze

- brakuje 1 typowego scenariusza testowego
- testy precyzji obliczeÅ„
- test wydajnoÅ›ciowe / odpornoÅ›ciowe

